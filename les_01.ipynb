{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 1,  1],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2],\n",
    "              [ 1,  5],\n",
    "              [ 1,  3],\n",
    "              [ 1,  0],\n",
    "              [ 1,  5],\n",
    "              [ 1, 10],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Подберите скорость обучения (eta) и количество итераций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae(y, y_pred):\n",
    "    err = np.mean(np.abs(y - y_pred))\n",
    "    return err\n",
    "\n",
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err\n",
    "\n",
    "def mserror(X, w, y):\n",
    "    y_pred = X.dot(w)\n",
    "    return (np.sum((y_pred - y)**2)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.1        \n",
      "Initial weights = [1.  0.5] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "\n",
    "eta = 0.1 #меняю коэффициент\n",
    "n_iter = 150 #меняю коэффициент\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "#Добавил отражение времени выполнение скрипта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0: W_new = [11.8 38.2], MSE = 3047.75\n",
      "Iteration #10: W_new = [12651.73553914 69617.0969639 ], MSE = 18310954068.05\n",
      "Iteration #20: W_new = [ 7732434.81888021 42641607.37852186], MSE = 9128819654907568.0\n",
      "Iteration #30: W_new = [1.06344502e+09 5.86454589e+09], MSE = 2.327920364266843e+20\n",
      "Iteration #40: W_new = [3.00127077e+10 1.65510116e+11], MSE = 2.545133529815933e+23\n",
      "Iteration #50: W_new = [1.55345341e+11 8.56677968e+11], MSE = 9.572295620500074e+24\n",
      "Iteration #60: W_new = [1.27742291e+11 7.04456313e+11], MSE = 9.351480126475957e+24\n",
      "Iteration #70: W_new = [1.38141953e+10 7.61806995e+10], MSE = 1.640858952828383e+23\n",
      "Iteration #80: W_new = [1.51674189e+08 8.36432543e+08], MSE = 3.125533537874439e+19\n",
      "Iteration #90: W_new = [116395.49988139 641638.79864291], MSE = 31317286806394.04\n",
      "Iteration #100: W_new = [48.41966454 22.99883908], MSE = 53518.86\n",
      "Iteration #110: W_new = [44.9771605   3.82798314], MSE = 43.97\n",
      "Iteration #120: W_new = [44.99895429  3.82402303], MSE = 43.97\n",
      "Iteration #130: W_new = [45.01387996  3.82131649], MSE = 43.97\n",
      "Iteration #140: W_new = [45.024372    3.81941392], MSE = 43.97\n",
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for k in range(W.shape[0]):\n",
    "        W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "    if i % 10 == 0:\n",
    "        eta /= 1.1\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Достаточная точность достигается при скорости 0.1 и количестве итераций 150\n",
    "\n",
    "Увеличение кол-ва итераций приводит к пропорциональному увеличению времени работы скрипта (16ms при 150 и 34.5 ms при 300)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2*. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0: W_new = [45.06138476  3.81270223], MSE = 43.97\n",
      "Iteration #10: W_new = [45.06160566  3.81266217], MSE = 43.97\n",
      "Iteration #20: W_new = [45.06178281  3.81263005], MSE = 43.97\n",
      "Iteration #30: W_new = [45.06192487  3.81260429], MSE = 43.97\n",
      "Iteration #40: W_new = [45.06203879  3.81258363], MSE = 43.97\n",
      "Iteration #50: W_new = [45.06213014  3.81256707], MSE = 43.97\n",
      "Iteration #60: W_new = [45.0622034   3.81255378], MSE = 43.97\n",
      "Iteration #70: W_new = [45.06226215  3.81254313], MSE = 43.97\n",
      "Iteration #80: W_new = [45.06230926  3.81253459], MSE = 43.97\n",
      "Iteration #90: W_new = [45.06234704  3.81252774], MSE = 43.97\n",
      "Iteration #100: W_new = [45.06237734  3.81252224], MSE = 43.97\n",
      "Iteration #110: W_new = [45.06240164  3.81251784], MSE = 43.97\n",
      "Iteration #120: W_new = [45.06242112  3.8125143 ], MSE = 43.97\n",
      "Iteration #130: W_new = [45.06243674  3.81251147], MSE = 43.97\n",
      "Iteration #140: W_new = [45.06244927  3.8125092 ], MSE = 43.97\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#     for k in range(W.shape[0]):\n",
    "#         W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "    # ИЗМЕНЕНИЯ\n",
    "    \n",
    "    W -= eta * 2/n * np.dot(X.T, y_pred - y) # ИЗМЕНЕНИЯ: транспонируем\n",
    "    \n",
    "    # ИЗМЕНЕНИЯ\n",
    "    #\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3*. Вместо того, чтобы задавать количество итераций, задайте другое условие останова алгоритма - когда веса перестают изменяться меньше определенного порога $\\epsilon$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list = [W.copy()]\n",
    "\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "weight_dist = np.inf\n",
    "\n",
    "errors = []\n",
    "\n",
    "iter_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: error - 43.96875000077936, weights: [45.06245932  3.81250738]\n",
      "Iter 1: error - 43.968750000745686, weights: [45.06246021  3.81250722]\n",
      "Iter 2: error - 43.968750000713484, weights: [45.06246108  3.81250706]\n",
      "Iter 3: error - 43.968750000682675, weights: [45.06246193  3.8125069 ]\n",
      "Iter 4: error - 43.96875000065319, weights: [45.06246276  3.81250675]\n",
      "Iter 5: error - 43.968750000624986, weights: [45.06246357  3.81250661]\n",
      "Iter 6: error - 43.96875000059799, weights: [45.06246437  3.81250646]\n",
      "Iter 7: error - 43.968750000572165, weights: [45.06246515  3.81250632]\n",
      "Iter 8: error - 43.96875000054745, weights: [45.06246591  3.81250618]\n",
      "Iter 9: error - 43.96875000052382, weights: [45.06246665  3.81250605]\n",
      "Iter 10: error - 43.96875000050119, weights: [45.06246738  3.81250592]\n",
      "Iter 11: error - 43.968750000479545, weights: [45.06246809  3.81250579]\n",
      "Iter 12: error - 43.968750000458826, weights: [45.06246879  3.81250566]\n",
      "Iter 13: error - 43.968750000439016, weights: [45.06246947  3.81250554]\n",
      "Iter 14: error - 43.968750000420066, weights: [45.06247014  3.81250542]\n",
      "Iter 15: error - 43.96875000040192, weights: [45.06247079  3.8125053 ]\n",
      "Iter 16: error - 43.96875000038456, weights: [45.06247143  3.81250518]\n",
      "Iter 17: error - 43.96875000036795, weights: [45.06247205  3.81250507]\n",
      "Iter 18: error - 43.96875000035205, weights: [45.06247266  3.81250496]\n",
      "Iter 19: error - 43.96875000033685, weights: [45.06247326  3.81250485]\n",
      "Iter 20: error - 43.9687500003223, weights: [45.06247384  3.81250474]\n",
      "Iter 21: error - 43.96875000030839, weights: [45.06247441  3.81250464]\n",
      "Iter 22: error - 43.96875000029506, weights: [45.06247497  3.81250454]\n",
      "Iter 23: error - 43.96875000028233, weights: [45.06247552  3.81250444]\n",
      "Iter 24: error - 43.96875000027014, weights: [45.06247605  3.81250434]\n",
      "Iter 25: error - 43.96875000025847, weights: [45.06247657  3.81250425]\n",
      "Iter 26: error - 43.968750000247304, weights: [45.06247709  3.81250416]\n",
      "Iter 27: error - 43.968750000236625, weights: [45.06247759  3.81250406]\n",
      "Iter 28: error - 43.96875000022639, weights: [45.06247808  3.81250398]\n",
      "Iter 29: error - 43.96875000021663, weights: [45.06247855  3.81250389]\n",
      "Iter 30: error - 43.96875000020727, weights: [45.06247902  3.8125038 ]\n",
      "Iter 31: error - 43.96875000019832, weights: [45.06247948  3.81250372]\n",
      "Iter 32: error - 43.96875000018976, weights: [45.06247993  3.81250364]\n",
      "Iter 33: error - 43.96875000018156, weights: [45.06248037  3.81250356]\n",
      "Iter 34: error - 43.96875000017373, weights: [45.0624808   3.81250348]\n",
      "Iter 35: error - 43.96875000016621, weights: [45.06248121  3.81250341]\n",
      "Iter 36: error - 43.968750000159034, weights: [45.06248162  3.81250333]\n",
      "Iter 37: error - 43.96875000015216, weights: [45.06248203  3.81250326]\n",
      "Iter 38: error - 43.968750000145604, weights: [45.06248242  3.81250319]\n",
      "Iter 39: error - 43.96875000013931, weights: [45.0624828   3.81250312]\n",
      "Iter 40: error - 43.96875000013329, weights: [45.06248318  3.81250305]\n",
      "Iter 41: error - 43.96875000012752, weights: [45.06248354  3.81250298]\n",
      "Iter 42: error - 43.96875000012203, weights: [45.0624839   3.81250292]\n",
      "Iter 43: error - 43.968750000116756, weights: [45.06248426  3.81250286]\n",
      "Iter 44: error - 43.96875000011171, weights: [45.0624846   3.81250279]\n",
      "Iter 45: error - 43.968750000106894, weights: [45.06248494  3.81250273]\n",
      "Iter 46: error - 43.968750000102276, weights: [45.06248526  3.81250267]\n",
      "Iter 47: error - 43.968750000097856, weights: [45.06248559  3.81250261]\n",
      "Iter 48: error - 43.968750000093635, weights: [45.0624859   3.81250256]\n",
      "Iter 49: error - 43.968750000089585, weights: [45.06248621  3.8125025 ]\n",
      "Iter 50: error - 43.968750000085734, weights: [45.06248651  3.81250245]\n",
      "Iter 51: error - 43.96875000008201, weights: [45.0624868   3.81250239]\n",
      "Iter 52: error - 43.96875000007849, weights: [45.06248709  3.81250234]\n",
      "Iter 53: error - 43.96875000007509, weights: [45.06248737  3.81250229]\n",
      "Iter 54: error - 43.96875000007184, weights: [45.06248765  3.81250224]\n",
      "Iter 55: error - 43.96875000006874, weights: [45.06248792  3.81250219]\n",
      "Iter 56: error - 43.96875000006577, weights: [45.06248818  3.81250214]\n",
      "Iter 57: error - 43.968750000062926, weights: [45.06248844  3.8125021 ]\n",
      "Iter 58: error - 43.96875000006021, weights: [45.06248869  3.81250205]\n",
      "Iter 59: error - 43.9687500000576, weights: [45.06248894  3.81250201]\n",
      "Iter 60: error - 43.96875000005513, weights: [45.06248918  3.81250196]\n",
      "Iter 61: error - 43.96875000005274, weights: [45.06248942  3.81250192]\n",
      "Iter 62: error - 43.96875000005046, weights: [45.06248965  3.81250188]\n",
      "Iter 63: error - 43.96875000004828, weights: [45.06248987  3.81250184]\n",
      "Iter 64: error - 43.96875000004619, weights: [45.0624901  3.8125018]\n",
      "Iter 65: error - 43.96875000004421, weights: [45.06249031  3.81250176]\n",
      "Iter 66: error - 43.96875000004229, weights: [45.06249052  3.81250172]\n",
      "Iter 67: error - 43.96875000004046, weights: [45.06249073  3.81250168]\n",
      "Iter 68: error - 43.96875000003871, weights: [45.06249093  3.81250164]\n",
      "Iter 69: error - 43.96875000003705, weights: [45.06249113  3.81250161]\n",
      "Iter 70: error - 43.96875000003545, weights: [45.06249132  3.81250157]\n",
      "Iter 71: error - 43.96875000003392, weights: [45.06249151  3.81250154]\n",
      "Iter 72: error - 43.96875000003245, weights: [45.0624917   3.81250151]\n",
      "Iter 73: error - 43.96875000003106, weights: [45.06249188  3.81250147]\n",
      "Iter 74: error - 43.96875000002971, weights: [45.06249206  3.81250144]\n",
      "Iter 75: error - 43.968750000028415, weights: [45.06249223  3.81250141]\n",
      "Iter 76: error - 43.96875000002719, weights: [45.0624924   3.81250138]\n",
      "Iter 77: error - 43.968750000026034, weights: [45.06249257  3.81250135]\n",
      "Iter 78: error - 43.968750000024905, weights: [45.06249273  3.81250132]\n",
      "Iter 79: error - 43.96875000002383, weights: [45.06249289  3.81250129]\n",
      "Iter 80: error - 43.968750000022794, weights: [45.06249304  3.81250126]\n",
      "Iter 81: error - 43.968750000021814, weights: [45.06249319  3.81250123]\n",
      "Iter 82: error - 43.96875000002086, weights: [45.06249334  3.81250121]\n",
      "Iter 83: error - 43.96875000001997, weights: [45.06249349  3.81250118]\n",
      "Iter 84: error - 43.96875000001911, weights: [45.06249363  3.81250115]\n",
      "Iter 85: error - 43.96875000001828, weights: [45.06249377  3.81250113]\n",
      "Iter 86: error - 43.968750000017494, weights: [45.06249391  3.81250111]\n",
      "Iter 87: error - 43.96875000001673, weights: [45.06249404  3.81250108]\n",
      "Iter 88: error - 43.968750000016016, weights: [45.06249417  3.81250106]\n",
      "Iter 89: error - 43.968750000015326, weights: [45.0624943   3.81250103]\n",
      "Iter 90: error - 43.96875000001466, weights: [45.06249442  3.81250101]\n",
      "Iter 91: error - 43.968750000014026, weights: [45.06249454  3.81250099]\n",
      "Iter 92: error - 43.96875000001342, weights: [45.06249466  3.81250097]\n",
      "Iter 93: error - 43.96875000001283, weights: [45.06249478  3.81250095]\n",
      "Iter 94: error - 43.968750000012285, weights: [45.06249489  3.81250093]\n",
      "Iter 95: error - 43.96875000001175, weights: [45.062495    3.81250091]\n",
      "Iter 96: error - 43.96875000001124, weights: [45.06249511  3.81250089]\n",
      "Iter 97: error - 43.968750000010765, weights: [45.06249522  3.81250087]\n",
      "Iter 98: error - 43.96875000001029, weights: [45.06249532  3.81250085]\n",
      "Iter 99: error - 43.968750000009855, weights: [45.06249543  3.81250083]\n",
      "Iter 100: error - 43.96875000000942, weights: [45.06249553  3.81250081]\n",
      "Iter 101: error - 43.968750000009024, weights: [45.06249562  3.81250079]\n",
      "Iter 102: error - 43.968750000008626, weights: [45.06249572  3.81250078]\n",
      "Iter 103: error - 43.96875000000826, weights: [45.06249581  3.81250076]\n",
      "Iter 104: error - 43.968750000007894, weights: [45.0624959   3.81250074]\n",
      "Iter 105: error - 43.968750000007574, weights: [45.06249599  3.81250073]\n",
      "Iter 106: error - 43.96875000000725, weights: [45.06249608  3.81250071]\n",
      "Iter 107: error - 43.96875000000692, weights: [45.06249617  3.8125007 ]\n",
      "Iter 108: error - 43.968750000006615, weights: [45.06249625  3.81250068]\n",
      "Iter 109: error - 43.968750000006345, weights: [45.06249633  3.81250067]\n",
      "Iter 110: error - 43.96875000000606, weights: [45.06249641  3.81250065]\n",
      "Iter 111: error - 43.96875000000581, weights: [45.06249649  3.81250064]\n",
      "Iter 112: error - 43.96875000000554, weights: [45.06249657  3.81250062]\n",
      "Iter 113: error - 43.968750000005315, weights: [45.06249664  3.81250061]\n",
      "Iter 114: error - 43.96875000000507, weights: [45.06249672  3.8125006 ]\n",
      "Iter 115: error - 43.96875000000486, weights: [45.06249679  3.81250058]\n",
      "Iter 116: error - 43.96875000000466, weights: [45.06249686  3.81250057]\n",
      "Iter 117: error - 43.96875000000445, weights: [45.06249693  3.81250056]\n",
      "Iter 118: error - 43.96875000000425, weights: [45.06249699  3.81250055]\n",
      "Iter 119: error - 43.96875000000407, weights: [45.06249706  3.81250053]\n",
      "Iter 120: error - 43.9687500000039, weights: [45.06249712  3.81250052]\n",
      "Iter 121: error - 43.96875000000373, weights: [45.06249719  3.81250051]\n",
      "Iter 122: error - 43.968750000003574, weights: [45.06249725  3.8125005 ]\n",
      "Iter 123: error - 43.968750000003425, weights: [45.06249731  3.81250049]\n",
      "Iter 124: error - 43.96875000000326, weights: [45.06249737  3.81250048]\n",
      "Iter 125: error - 43.968750000003126, weights: [45.06249742  3.81250047]\n",
      "Iter 126: error - 43.96875000000299, weights: [45.06249748  3.81250046]\n",
      "Iter 127: error - 43.968750000002856, weights: [45.06249753  3.81250045]\n",
      "Iter 128: error - 43.96875000000274, weights: [45.06249759  3.81250044]\n",
      "Iter 129: error - 43.96875000000263, weights: [45.06249764  3.81250043]\n",
      "Iter 130: error - 43.968750000002515, weights: [45.06249769  3.81250042]\n",
      "Iter 131: error - 43.968750000002395, weights: [45.06249774  3.81250041]\n",
      "Iter 132: error - 43.96875000000229, weights: [45.06249779  3.8125004 ]\n",
      "Iter 133: error - 43.9687500000022, weights: [45.06249784  3.81250039]\n",
      "Iter 134: error - 43.9687500000021, weights: [45.06249789  3.81250038]\n",
      "Iter 135: error - 43.96875000000201, weights: [45.06249793  3.81250037]\n",
      "Iter 136: error - 43.96875000000193, weights: [45.06249798  3.81250037]\n",
      "Iter 137: error - 43.96875000000184, weights: [45.06249802  3.81250036]\n",
      "Iter 138: error - 43.96875000000176, weights: [45.06249807  3.81250035]\n",
      "Iter 139: error - 43.96875000000169, weights: [45.06249811  3.81250034]\n",
      "Iter 140: error - 43.968750000001606, weights: [45.06249815  3.81250034]\n",
      "Iter 141: error - 43.96875000000155, weights: [45.06249819  3.81250033]\n",
      "Iter 142: error - 43.96875000000148, weights: [45.06249823  3.81250032]\n",
      "Iter 143: error - 43.968750000001414, weights: [45.06249827  3.81250031]\n",
      "Iter 144: error - 43.96875000000135, weights: [45.06249831  3.81250031]\n",
      "Iter 145: error - 43.96875000000129, weights: [45.06249834  3.8125003 ]\n",
      "Iter 146: error - 43.96875000000125, weights: [45.06249838  3.81250029]\n",
      "Iter 147: error - 43.96875000000118, weights: [45.06249841  3.81250029]\n",
      "Iter 148: error - 43.96875000000112, weights: [45.06249845  3.81250028]\n",
      "Iter 149: error - 43.96875000000108, weights: [45.06249848  3.81250028]\n",
      "Iter 150: error - 43.96875000000104, weights: [45.06249852  3.81250027]\n",
      "Iter 151: error - 43.96875000000098, weights: [45.06249855  3.81250026]\n",
      "Iter 152: error - 43.96875000000095, weights: [45.06249858  3.81250026]\n",
      "Iter 153: error - 43.96875000000091, weights: [45.06249861  3.81250025]\n",
      "Iter 154: error - 43.96875000000088, weights: [45.06249864  3.81250025]\n",
      "Iter 155: error - 43.96875000000083, weights: [45.06249867  3.81250024]\n",
      "Iter 156: error - 43.9687500000008, weights: [45.0624987   3.81250024]\n",
      "Iter 157: error - 43.968750000000774, weights: [45.06249873  3.81250023]\n",
      "Iter 158: error - 43.968750000000725, weights: [45.06249876  3.81250023]\n",
      "Iter 159: error - 43.968750000000696, weights: [45.06249878  3.81250022]\n",
      "Iter 160: error - 43.968750000000675, weights: [45.06249881  3.81250022]\n",
      "Iter 161: error - 43.96875000000063, weights: [45.06249884  3.81250021]\n",
      "Iter 162: error - 43.96875000000061, weights: [45.06249886  3.81250021]\n",
      "Iter 163: error - 43.96875000000059, weights: [45.06249889  3.8125002 ]\n",
      "Iter 164: error - 43.968750000000554, weights: [45.06249891  3.8125002 ]\n",
      "Iter 165: error - 43.96875000000053, weights: [45.06249893  3.81250019]\n",
      "Iter 166: error - 43.968750000000504, weights: [45.06249896  3.81250019]\n",
      "Iter 167: error - 43.96875000000049, weights: [45.06249898  3.81250018]\n",
      "Iter 168: error - 43.96875000000047, weights: [45.062499    3.81250018]\n",
      "Iter 169: error - 43.96875000000044, weights: [45.06249902  3.81250018]\n",
      "Iter 170: error - 43.96875000000043, weights: [45.06249905  3.81250017]\n",
      "Iter 171: error - 43.968750000000405, weights: [45.06249907  3.81250017]\n",
      "Iter 172: error - 43.9687500000004, weights: [45.06249909  3.81250017]\n",
      "Iter 173: error - 43.968750000000384, weights: [45.06249911  3.81250016]\n",
      "Iter 174: error - 43.96875000000036, weights: [45.06249913  3.81250016]\n",
      "Iter 175: error - 43.96875000000034, weights: [45.06249915  3.81250015]\n",
      "Iter 176: error - 43.96875000000033, weights: [45.06249916  3.81250015]\n",
      "Iter 177: error - 43.96875000000033, weights: [45.06249918  3.81250015]\n",
      "Iter 178: error - 43.9687500000003, weights: [45.0624992   3.81250015]\n",
      "Iter 179: error - 43.96875000000028, weights: [45.06249922  3.81250014]\n",
      "Iter 180: error - 43.96875000000028, weights: [45.06249923  3.81250014]\n",
      "Iter 181: error - 43.96875000000027, weights: [45.06249925  3.81250014]\n",
      "Iter 182: error - 43.968750000000256, weights: [45.06249927  3.81250013]\n",
      "Iter 183: error - 43.96875000000024, weights: [45.06249928  3.81250013]\n",
      "Iter 184: error - 43.968750000000234, weights: [45.0624993   3.81250013]\n",
      "Iter 185: error - 43.96875000000021, weights: [45.06249931  3.81250012]\n",
      "Iter 186: error - 43.96875000000021, weights: [45.06249933  3.81250012]\n",
      "Iter 187: error - 43.9687500000002, weights: [45.06249934  3.81250012]\n",
      "Iter 188: error - 43.96875000000019, weights: [45.06249936  3.81250012]\n",
      "Iter 189: error - 43.968750000000185, weights: [45.06249937  3.81250011]\n",
      "Iter 190: error - 43.968750000000185, weights: [45.06249939  3.81250011]\n",
      "Iter 191: error - 43.968750000000156, weights: [45.0624994   3.81250011]\n",
      "Iter 192: error - 43.96875000000016, weights: [45.06249941  3.81250011]\n",
      "Iter 193: error - 43.968750000000156, weights: [45.06249943  3.8125001 ]\n",
      "Iter 194: error - 43.968750000000156, weights: [45.06249944  3.8125001 ]\n",
      "Iter 195: error - 43.968750000000135, weights: [45.06249945  3.8125001 ]\n",
      "Iter 196: error - 43.96875000000013, weights: [45.06249946  3.8125001 ]\n",
      "Iter 197: error - 43.96875000000013, weights: [45.06249947  3.8125001 ]\n",
      "Iter 198: error - 43.96875000000012, weights: [45.06249949  3.81250009]\n",
      "Iter 199: error - 43.96875000000013, weights: [45.0624995   3.81250009]\n",
      "Iter 200: error - 43.96875000000013, weights: [45.06249951  3.81250009]\n",
      "Iter 201: error - 43.9687500000001, weights: [45.06249952  3.81250009]\n",
      "Iter 202: error - 43.9687500000001, weights: [45.06249953  3.81250009]\n",
      "Iter 203: error - 43.9687500000001, weights: [45.06249954  3.81250008]\n",
      "Iter 204: error - 43.9687500000001, weights: [45.06249955  3.81250008]\n",
      "Iter 205: error - 43.9687500000001, weights: [45.06249956  3.81250008]\n",
      "В случае использования градиентного спуска функционал ошибки составляет 43.9688\n"
     ]
    }
   ],
   "source": [
    "while weight_dist > min_weight_dist:\n",
    "    y_pred = np.dot(X, W)\n",
    "    dQ = 2/n * X.T @ (X @ W - y)\n",
    "    new_w = W - eta * dQ\n",
    "    weight_dist = np.linalg.norm(new_w - W, ord=2)\n",
    "    error = mserror(X, new_w, y)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors.append(error)\n",
    "    \n",
    "    print(f'Iter {iter_num}: error - {error}, weights: {new_w}')\n",
    "    \n",
    "    iter_num += 1\n",
    "    W = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "w_pred = w_list[-1]\n",
    "\n",
    "print(f'В случае использования градиентного спуска функционал ошибки составляет {round(errors[-1], 4)}')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
